{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practico Redes Neuronales\n",
    "\n",
    "Librerias a usar:\n",
    "- tensorflow >= 1.13.1\n",
    "- tensorboard >= 1.13.1\n",
    "- keras >= 2.2.4\n",
    "- Pillow >= 6.0.0\n",
    "- scikit-learn >= 0.20.3\n",
    "\n",
    "## Ejercicio 1: Entrenamiento\n",
    "\n",
    "- Descargue y lea el paper [Using Artificial Intelligence to Predict the Equilibrated Postdialysis Blood Urea Concentration](https://drive.google.com/open?id=1TEcpoTI6mCEhvfpZv3Gp1GBr6uA0Erfg). Utilize redes neuronales para implementar el modelo propuesto en dicha publicacion. Utilice los siguientes [datos](https://drive.google.com/open?id=17bIDVoixcTlUv2JaCDRBRsU1g-WPwnBj) para el entrenamiento. Ayuda: [Tutorial Keras](https://keras.io/getting-started/sequential-model-guide/#examples).\n",
    "- Si bien se presenta e intenta resolver un problema de regresion, podemos convertirlo en clasificacion utilizando Ueq > 35 como punto de corte. Genere dicha conversion de datos, asignandoles la clase 0 para Ueq < 35 y 1 en caso contrario. Entrene una red de clasificacion.\n",
    "\n",
    "## Ejercicio 2: Extraccion de caracteristicas\n",
    "\n",
    "- Descargue el dataset **[pets](https://drive.google.com/open?id=1JyuO-CNruuUdj14SW4s1RExBa3gMhjBi)** con imagenes de gatos y perros.\n",
    "- Revise y elija dos redes convolucionales pre-entrenadas en *imagenet* de la [pagina](https://keras.io/applications/) de modelos de Keras.\n",
    "- Genere dos bases de datos con vectores de caracteristicas (features) extraidos utilizando los modelos elegidos en el dataset de mascotas.\n",
    "    - Tip 1: NO cargue cada imagen introduciendo a mano la ruta a el archivo. Utilice Python para iterar por todo el dataset y cargar los archivos.\n",
    "    - Tip 2: Recuerde que cada modelo requiere antes un pre-procesamiento de las imagenes.\n",
    "    - Tip 3: Si carga las imagenes con OpenCV estaran en formato BGR, Keras por defecto usa RGB, recuerde convertir los canales de color.\n",
    "- Entrene una red neuronal para cada dataset con el objetivo de clasificar entre perros y gatos. Compare los resultados obtenidos entre ambas bases de datos en terminos de accuracy pero tambien en velocidad (que modelo de extraccion de features es mas rapido?).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy import misc  \n",
    "from PIL import Image  \n",
    "import glob  \n",
    "import matplotlib.pyplot as plt  \n",
    "import scipy.misc  \n",
    "from matplotlib.pyplot import imshow  \n",
    "%matplotlib inline\n",
    "from IPython.display import SVG  \n",
    "import cv2  \n",
    "import seaborn as sn  \n",
    "import pandas as pd  \n",
    "import pickle  \n",
    "from keras import layers  \n",
    "from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout  \n",
    "from keras.models import Sequential, Model, load_model  \n",
    "from keras.preprocessing import image  \n",
    "from keras.preprocessing.image import load_img  \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.applications.imagenet_utils import decode_predictions  \n",
    "from keras.utils import layer_utils, np_utils  \n",
    "from keras.utils.data_utils import get_file  \n",
    "from keras.applications.imagenet_utils import preprocess_input  \n",
    "from keras.utils.vis_utils import model_to_dot  \n",
    "from keras.utils import plot_model  \n",
    "from keras.initializers import glorot_uniform  \n",
    "from keras import losses  \n",
    "import keras.backend as K  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "import tensorflow as tf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(x_train_original, y_train_original), (x_test_original, y_test_original) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19],\n",
       "       [29],\n",
       "       [ 0],\n",
       "       ...,\n",
       "       [ 3],\n",
       "       [ 7],\n",
       "       [73]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [195, 205, 193],\n",
       "         [212, 224, 204],\n",
       "         [182, 194, 167]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [170, 176, 150],\n",
       "         [161, 168, 130],\n",
       "         [146, 154, 113]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [189, 199, 169],\n",
       "         [166, 178, 130],\n",
       "         [121, 133,  87]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[148, 185,  79],\n",
       "         [142, 182,  57],\n",
       "         [140, 179,  60],\n",
       "         ...,\n",
       "         [ 30,  17,   1],\n",
       "         [ 65,  62,  15],\n",
       "         [ 76,  77,  20]],\n",
       "\n",
       "        [[122, 157,  66],\n",
       "         [120, 155,  58],\n",
       "         [126, 160,  71],\n",
       "         ...,\n",
       "         [ 22,  16,   3],\n",
       "         [ 97, 112,  56],\n",
       "         [141, 161,  87]],\n",
       "\n",
       "        [[ 87, 122,  41],\n",
       "         [ 88, 122,  39],\n",
       "         [101, 134,  56],\n",
       "         ...,\n",
       "         [ 34,  36,  10],\n",
       "         [105, 133,  59],\n",
       "         [138, 173,  79]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [255, 255, 255]]],\n",
       "\n",
       "\n",
       "       [[[250, 250, 248],\n",
       "         [248, 249, 243],\n",
       "         [247, 248, 239],\n",
       "         ...,\n",
       "         [250, 250, 246],\n",
       "         [250, 250, 246],\n",
       "         [249, 250, 246]],\n",
       "\n",
       "        [[250, 251, 245],\n",
       "         [248, 249, 238],\n",
       "         [247, 247, 234],\n",
       "         ...,\n",
       "         [251, 251, 242],\n",
       "         [251, 252, 243],\n",
       "         [250, 251, 243]],\n",
       "\n",
       "        [[251, 251, 244],\n",
       "         [250, 248, 237],\n",
       "         [250, 245, 233],\n",
       "         ...,\n",
       "         [250, 249, 238],\n",
       "         [250, 249, 240],\n",
       "         [250, 249, 242]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[221, 213, 191],\n",
       "         [221, 206, 176],\n",
       "         [225, 207, 181],\n",
       "         ...,\n",
       "         [199, 176, 134],\n",
       "         [207, 193, 165],\n",
       "         [233, 229, 226]],\n",
       "\n",
       "        [[225, 223, 204],\n",
       "         [227, 219, 196],\n",
       "         [229, 216, 200],\n",
       "         ...,\n",
       "         [204, 185, 151],\n",
       "         [212, 201, 180],\n",
       "         [234, 232, 228]],\n",
       "\n",
       "        [[233, 233, 226],\n",
       "         [234, 232, 224],\n",
       "         [235, 230, 225],\n",
       "         ...,\n",
       "         [219, 209, 194],\n",
       "         [223, 216, 207],\n",
       "         [232, 230, 228]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[248, 244, 242],\n",
       "         [240, 232, 223],\n",
       "         [236, 232, 223],\n",
       "         ...,\n",
       "         [233, 229, 222],\n",
       "         [230, 228, 222],\n",
       "         [238, 237, 233]],\n",
       "\n",
       "        [[225, 213, 204],\n",
       "         [186, 167, 149],\n",
       "         [175, 159, 140],\n",
       "         ...,\n",
       "         [163, 148, 134],\n",
       "         [156, 144, 133],\n",
       "         [192, 184, 176]],\n",
       "\n",
       "        [[209, 194, 179],\n",
       "         [144, 120,  95],\n",
       "         [139, 115,  87],\n",
       "         ...,\n",
       "         [109,  86,  67],\n",
       "         [109,  90,  76],\n",
       "         [157, 145, 135]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[161, 159, 153],\n",
       "         [ 39,  34,  28],\n",
       "         [ 28,  20,  14],\n",
       "         ...,\n",
       "         [ 93,  72,  53],\n",
       "         [ 85,  67,  50],\n",
       "         [136, 126, 115]],\n",
       "\n",
       "        [[181, 179, 172],\n",
       "         [ 86,  83,  77],\n",
       "         [ 71,  68,  62],\n",
       "         ...,\n",
       "         [122, 103,  89],\n",
       "         [105,  92,  82],\n",
       "         [151, 145, 141]],\n",
       "\n",
       "        [[224, 223, 218],\n",
       "         [180, 180, 175],\n",
       "         [173, 172, 167],\n",
       "         ...,\n",
       "         [196, 187, 180],\n",
       "         [183, 178, 174],\n",
       "         [204, 205, 205]]],\n",
       "\n",
       "\n",
       "       [[[156, 154, 137],\n",
       "         [151, 146, 123],\n",
       "         [151, 144, 125],\n",
       "         ...,\n",
       "         [155, 150, 129],\n",
       "         [152, 148, 125],\n",
       "         [186, 184, 163]],\n",
       "\n",
       "        [[110, 106,  77],\n",
       "         [116, 108,  62],\n",
       "         [114, 101,  57],\n",
       "         ...,\n",
       "         [116, 106,  61],\n",
       "         [111, 103,  56],\n",
       "         [134, 129,  92]],\n",
       "\n",
       "        [[116, 112,  82],\n",
       "         [124, 118,  66],\n",
       "         [128, 118,  67],\n",
       "         ...,\n",
       "         [ 99,  84,  43],\n",
       "         [101,  87,  43],\n",
       "         [129, 118,  86]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[109, 101,  74],\n",
       "         [112, 100,  54],\n",
       "         [118, 105,  62],\n",
       "         ...,\n",
       "         [126, 113,  65],\n",
       "         [126, 111,  61],\n",
       "         [138, 124,  89]],\n",
       "\n",
       "        [[ 98,  92,  63],\n",
       "         [ 93,  82,  35],\n",
       "         [ 96,  83,  38],\n",
       "         ...,\n",
       "         [112,  96,  47],\n",
       "         [109,  92,  45],\n",
       "         [127, 113,  80]],\n",
       "\n",
       "        [[170, 167, 145],\n",
       "         [160, 153, 118],\n",
       "         [163, 152, 119],\n",
       "         ...,\n",
       "         [161, 151, 114],\n",
       "         [156, 144, 107],\n",
       "         [163, 154, 126]]],\n",
       "\n",
       "\n",
       "       [[[ 31,  67, 122],\n",
       "         [ 30,  68, 124],\n",
       "         [ 31,  69, 126],\n",
       "         ...,\n",
       "         [ 32,  70, 129],\n",
       "         [ 32,  70, 125],\n",
       "         [ 32,  69, 122]],\n",
       "\n",
       "        [[ 29,  68, 126],\n",
       "         [ 28,  69, 128],\n",
       "         [ 30,  69, 130],\n",
       "         ...,\n",
       "         [ 32,  70, 131],\n",
       "         [ 32,  69, 127],\n",
       "         [ 31,  69, 124]],\n",
       "\n",
       "        [[ 30,  67, 126],\n",
       "         [ 29,  68, 128],\n",
       "         [ 30,  69, 130],\n",
       "         ...,\n",
       "         [ 32,  72, 132],\n",
       "         [ 31,  70, 130],\n",
       "         [ 30,  69, 127]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 39,  41,  76],\n",
       "         [ 38,  42,  76],\n",
       "         [ 38,  44,  78],\n",
       "         ...,\n",
       "         [ 39,  44,  79],\n",
       "         [ 38,  42,  77],\n",
       "         [ 39,  41,  76]],\n",
       "\n",
       "        [[ 40,  39,  73],\n",
       "         [ 39,  40,  74],\n",
       "         [ 39,  41,  76],\n",
       "         ...,\n",
       "         [ 39,  41,  76],\n",
       "         [ 40,  41,  74],\n",
       "         [ 40,  39,  73]],\n",
       "\n",
       "        [[ 40,  39,  70],\n",
       "         [ 40,  39,  71],\n",
       "         [ 40,  39,  72],\n",
       "         ...,\n",
       "         [ 41,  38,  72],\n",
       "         [ 39,  38,  69],\n",
       "         [ 40,  37,  67]]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_original, 100)\n",
    "y_test = np_utils.to_categorical(y_test_original, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(x_train_original[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_original/255  \n",
    "x_test = x_test_original/255  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_nn():  \n",
    "  model = Sequential()\n",
    "  model.add(Flatten(input_shape=(32, 32, 3), name=\"Input_layer\"))\n",
    "  model.add(Dense(1000, activation='relu', name=\"Hidden_layer_1\"))\n",
    "  model.add(Dense(500, activation='relu', name=\"Hidden_layer_2\"))\n",
    "  model.add(Dense(100, activation='softmax', name=\"Output_layer\"))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "snn_model = create_simple_nn()  \n",
    "snn_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (Flatten)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "Hidden_layer_1 (Dense)       (None, 1000)              3073000   \n",
      "_________________________________________________________________\n",
      "Hidden_layer_2 (Dense)       (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "Output_layer (Dense)         (None, 100)               50100     \n",
      "=================================================================\n",
      "Total params: 3,623,600\n",
      "Trainable params: 3,623,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "snn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 36s 714us/step - loss: 4.1611 - acc: 0.0771 - mean_squared_error: 0.0097 - val_loss: 3.9154 - val_acc: 0.1112 - val_mean_squared_error: 0.0096\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 34s 678us/step - loss: 3.7723 - acc: 0.1347 - mean_squared_error: 0.0094 - val_loss: 3.7285 - val_acc: 0.1400 - val_mean_squared_error: 0.0094\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 31s 628us/step - loss: 3.6147 - acc: 0.1617 - mean_squared_error: 0.0093 - val_loss: 3.6207 - val_acc: 0.1607 - val_mean_squared_error: 0.0093\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 32s 643us/step - loss: 3.5147 - acc: 0.1818 - mean_squared_error: 0.0092 - val_loss: 3.5722 - val_acc: 0.1710 - val_mean_squared_error: 0.0092\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 31s 612us/step - loss: 3.4328 - acc: 0.1947 - mean_squared_error: 0.0091 - val_loss: 3.5079 - val_acc: 0.1821 - val_mean_squared_error: 0.0091\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 3.3596 - acc: 0.2086 - mean_squared_error: 0.0090 - val_loss: 3.4531 - val_acc: 0.1938 - val_mean_squared_error: 0.0091\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 31s 615us/step - loss: 3.2971 - acc: 0.2197 - mean_squared_error: 0.0089 - val_loss: 3.4677 - val_acc: 0.1911 - val_mean_squared_error: 0.0091\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 31s 619us/step - loss: 3.2364 - acc: 0.2317 - mean_squared_error: 0.0089 - val_loss: 3.4094 - val_acc: 0.2044 - val_mean_squared_error: 0.0090\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 31s 627us/step - loss: 3.1819 - acc: 0.2416 - mean_squared_error: 0.0088 - val_loss: 3.3481 - val_acc: 0.2121 - val_mean_squared_error: 0.0089\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 3.1298 - acc: 0.2503 - mean_squared_error: 0.0087 - val_loss: 3.3241 - val_acc: 0.2171 - val_mean_squared_error: 0.0089\n"
     ]
    }
   ],
   "source": [
    "snn = snn_model.fit(x=x_train, y=y_train, batch_size=32, epochs=10, verbose=1, validation_data=(x_test, y_test), shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
