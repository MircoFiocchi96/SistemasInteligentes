{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import keras as ks\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "from IPython.display import Image\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPool2D, GlobalAveragePooling2D, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "weights = ks.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(f, l, m):\n",
    "    e_l = []\n",
    "    feat_l = []\n",
    "    for filename in tqdm(os.listdir(f)):\n",
    "        img_path = os.path.join(f, filename)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "        #feat = m.predict(x)\n",
    "\n",
    "        e_l.append(x)\n",
    "        feat_l.append(l)\n",
    "        \n",
    "    return e_l, feat_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(f):\n",
    "    img_path = os.path.join('', f)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = preprocess_input(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:07<00:00, 105.75it/s]\n"
     ]
    }
   ],
   "source": [
    "enfermos, feat_enfermos = load_images_from_folder('fondo_de_ojo_train/enfermo/', 0, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [00:08<00:00, 98.24it/s] \n"
     ]
    }
   ],
   "source": [
    "sanos, feat_sanos = load_images_from_folder('fondo_de_ojo_train/sano/', 1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sanos + enfermos\n",
    "Y = feat_sanos + feat_enfermos\n",
    "# suffle\n",
    "#np.random.shuffle(data)\n",
    "#data = np.array(data)\n",
    "#X = data[: , 0]\n",
    "#Y = data[:, 1]\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1313, 224, 224, 3) (1313,)\n",
      "Testing data shape :  (329, 224, 224, 3) (329,)\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(train_Y)\n",
    "nClasses = len(classes)\n",
    "nClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 1\n",
      "After conversion to one-hot: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]]],\n",
       "\n",
       "\n",
       "       [[[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]]],\n",
       "\n",
       "\n",
       "       [[[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]]],\n",
       "\n",
       "\n",
       "       [[[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]]],\n",
       "\n",
       "\n",
       "       [[[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]],\n",
       "\n",
       "        [[-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         ...,\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854],\n",
       "         [-0.00379854, -0.00379854, -0.00379854]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                12845088  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 12,846,050\n",
      "Trainable params: 12,846,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "mobile = Sequential()\n",
    "mobile.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(224,224,3)))\n",
    "mobile.add(LeakyReLU(alpha=0.1))\n",
    "mobile.add(MaxPooling2D((2, 2),padding='same'))\n",
    "mobile.add(Dropout(0.5))\n",
    "\n",
    "mobile.add(Flatten())\n",
    "mobile.add(Dense(32, activation='linear'))\n",
    "mobile.add(LeakyReLU(alpha=0.1))\n",
    "mobile.add(Dropout(0.5)) \n",
    "mobile.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "mobile.summary()\n",
    "\n",
    "mobile.compile(loss=ks.losses.categorical_crossentropy, optimizer=ks.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1050 samples, validate on 263 samples\n",
      "Epoch 1/150\n",
      "1050/1050 [==============================] - 35s 33ms/step - loss: 0.6997 - acc: 0.5171 - val_loss: 0.6933 - val_acc: 0.5399\n",
      "Epoch 2/150\n",
      "1050/1050 [==============================] - 33s 32ms/step - loss: 0.6907 - acc: 0.5190 - val_loss: 0.6903 - val_acc: 0.5361\n",
      "Epoch 3/150\n",
      "1050/1050 [==============================] - 36s 35ms/step - loss: 0.6899 - acc: 0.5267 - val_loss: 0.7038 - val_acc: 0.4715\n",
      "Epoch 4/150\n",
      "1050/1050 [==============================] - 38s 36ms/step - loss: 0.6883 - acc: 0.5238 - val_loss: 0.6894 - val_acc: 0.5361\n",
      "Epoch 5/150\n",
      "1050/1050 [==============================] - 38s 36ms/step - loss: 0.6872 - acc: 0.5524 - val_loss: 0.7064 - val_acc: 0.4981\n",
      "Epoch 6/150\n",
      "1050/1050 [==============================] - 39s 37ms/step - loss: 0.6863 - acc: 0.5600 - val_loss: 0.6895 - val_acc: 0.5133\n",
      "Epoch 7/150\n",
      "1050/1050 [==============================] - 36s 34ms/step - loss: 0.6797 - acc: 0.5848 - val_loss: 0.7237 - val_acc: 0.4525\n",
      "Epoch 8/150\n",
      "1050/1050 [==============================] - 38s 36ms/step - loss: 0.6824 - acc: 0.5552 - val_loss: 0.6866 - val_acc: 0.5133\n",
      "Epoch 9/150\n",
      "1050/1050 [==============================] - 35s 33ms/step - loss: 0.6803 - acc: 0.5590 - val_loss: 0.6963 - val_acc: 0.5589\n",
      "Epoch 10/150\n",
      "1050/1050 [==============================] - 35s 33ms/step - loss: 0.6758 - acc: 0.5638 - val_loss: 0.6874 - val_acc: 0.5323\n",
      "Epoch 11/150\n",
      "1050/1050 [==============================] - 35s 33ms/step - loss: 0.6768 - acc: 0.5733 - val_loss: 0.6932 - val_acc: 0.5665\n",
      "Epoch 12/150\n",
      "1050/1050 [==============================] - 36s 35ms/step - loss: 0.6788 - acc: 0.5810 - val_loss: 0.6863 - val_acc: 0.5551\n",
      "Epoch 13/150\n",
      "1050/1050 [==============================] - 35s 33ms/step - loss: 0.6729 - acc: 0.5781 - val_loss: 0.7036 - val_acc: 0.5399\n",
      "Epoch 14/150\n",
      "1050/1050 [==============================] - 34s 33ms/step - loss: 0.6755 - acc: 0.5743 - val_loss: 0.6854 - val_acc: 0.5741\n",
      "Epoch 15/150\n",
      "1050/1050 [==============================] - 35s 33ms/step - loss: 0.6709 - acc: 0.5952 - val_loss: 0.7090 - val_acc: 0.5361\n",
      "Epoch 16/150\n",
      "1050/1050 [==============================] - 34s 33ms/step - loss: 0.6724 - acc: 0.5876 - val_loss: 0.6873 - val_acc: 0.5779\n",
      "Epoch 17/150\n",
      "1050/1050 [==============================] - 35s 34ms/step - loss: 0.6701 - acc: 0.6067 - val_loss: 0.6825 - val_acc: 0.5817\n",
      "Epoch 18/150\n",
      "1050/1050 [==============================] - 38s 36ms/step - loss: 0.6647 - acc: 0.5952 - val_loss: 0.6873 - val_acc: 0.5779\n",
      "Epoch 19/150\n",
      "1050/1050 [==============================] - 35s 34ms/step - loss: 0.6710 - acc: 0.6048 - val_loss: 0.6802 - val_acc: 0.5970\n",
      "Epoch 20/150\n",
      "1050/1050 [==============================] - 37s 35ms/step - loss: 0.6650 - acc: 0.5981 - val_loss: 0.6810 - val_acc: 0.5589\n",
      "Epoch 21/150\n",
      "1050/1050 [==============================] - 37s 36ms/step - loss: 0.6681 - acc: 0.5886 - val_loss: 0.7155 - val_acc: 0.5285\n",
      "Epoch 22/150\n",
      "1050/1050 [==============================] - 37s 35ms/step - loss: 0.6604 - acc: 0.6038 - val_loss: 0.6882 - val_acc: 0.5856\n",
      "Epoch 23/150\n",
      "1050/1050 [==============================] - 39s 37ms/step - loss: 0.6591 - acc: 0.6181 - val_loss: 0.7042 - val_acc: 0.5513\n",
      "Epoch 24/150\n",
      "1050/1050 [==============================] - 40s 38ms/step - loss: 0.6637 - acc: 0.6086 - val_loss: 0.6839 - val_acc: 0.5551\n",
      "Epoch 25/150\n",
      "1050/1050 [==============================] - 38s 36ms/step - loss: 0.6628 - acc: 0.6210 - val_loss: 0.6818 - val_acc: 0.5665\n",
      "Epoch 26/150\n",
      "1050/1050 [==============================] - 38s 36ms/step - loss: 0.6558 - acc: 0.6333 - val_loss: 0.6773 - val_acc: 0.5551\n",
      "Epoch 27/150\n",
      "1050/1050 [==============================] - 37s 35ms/step - loss: 0.6613 - acc: 0.6190 - val_loss: 0.6757 - val_acc: 0.5894\n",
      "Epoch 28/150\n",
      "1050/1050 [==============================] - 37s 36ms/step - loss: 0.6533 - acc: 0.6295 - val_loss: 0.7032 - val_acc: 0.5437\n",
      "Epoch 29/150\n",
      "1050/1050 [==============================] - 37s 35ms/step - loss: 0.6589 - acc: 0.6276 - val_loss: 0.6844 - val_acc: 0.5817\n",
      "Epoch 30/150\n",
      "1050/1050 [==============================] - 36s 34ms/step - loss: 0.6498 - acc: 0.6467 - val_loss: 0.6820 - val_acc: 0.5627\n",
      "Epoch 31/150\n",
      "1050/1050 [==============================] - 36s 34ms/step - loss: 0.6565 - acc: 0.6143 - val_loss: 0.6799 - val_acc: 0.5817\n",
      "Epoch 32/150\n",
      "1050/1050 [==============================] - 37s 35ms/step - loss: 0.6545 - acc: 0.6352 - val_loss: 0.6763 - val_acc: 0.5970\n",
      "Epoch 33/150\n",
      " 768/1050 [====================>.........] - ETA: 9s - loss: 0.6453 - acc: 0.6328 "
     ]
    }
   ],
   "source": [
    "mobile_train_dropout = mobile.fit(train_X, train_Y, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 3s 10ms/step\n",
      "Test loss: 0.6929858323288544\n",
      "Test accuracy: 0.510638297962925\n"
     ]
    }
   ],
   "source": [
    "mobile_eval = mobile.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    " \n",
    "print('Test loss:', mobile_eval[0])\n",
    "print('Test accuracy:', mobile_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = mobile.predict(test_X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfermito = load_image('fondo_de_ojo_train/enfermo/train_enfermo1.jpg')\n",
    "sanito = load_image('fondo_de_ojo_train/sano/train_sano1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 224, 224, 3)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = enfermito/255\n",
    "n2 = sanito/255\n",
    "n = np.array([n1, n2])\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "predictions = mobile.predict(n)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
